 2024-05-13 13:12:28,450 -root -INFO -i am main method...
2024-05-13 13:12:28,450 -root -INFO -calling spark object...
2024-05-13 13:12:28,450 -Create_spark -INFO -get_spark_object method started
2024-05-13 13:12:28,450 -Create_spark -INFO -master is local
2024-05-13 13:12:38,093 -Create_spark -INFO -Spark object created .....
2024-05-13 13:12:38,093 -root -INFO -Validating Spark Object
2024-05-13 13:12:38,093 -Validate -WARNING -started the get_current_date method....
2024-05-13 13:12:41,390 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 13))]
2024-05-13 13:12:41,390 -root -WARNING -Validation done, go forward ...
2024-05-13 13:12:41,390 -root -INFO -Application Done
2024-05-13 16:29:58,905 -root -INFO -i am main method...
2024-05-13 16:29:58,905 -root -INFO -calling spark object...
2024-05-13 16:29:58,905 -Create_spark -INFO -get_spark_object method started
2024-05-13 16:29:58,905 -Create_spark -INFO -master is local
2024-05-13 16:30:07,391 -Create_spark -INFO -Spark object created .....
2024-05-13 16:30:07,392 -root -INFO -Validating Spark Object
2024-05-13 16:30:07,392 -Validate -WARNING -started the get_current_date method....
2024-05-13 16:30:10,447 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 13))]
2024-05-13 16:30:10,447 -root -WARNING -Validation done, go forward ...
2024-05-13 16:30:10,447 -root -INFO -Application Done
2024-05-16 12:12:29,964 -root -INFO -i am main method...
2024-05-16 12:12:29,964 -root -INFO -calling spark object...
2024-05-16 12:12:29,964 -Create_spark -INFO -get_spark_object method started
2024-05-16 12:12:29,964 -Create_spark -INFO -master is local
2024-05-16 12:12:39,178 -Create_spark -INFO -Spark object created .....
2024-05-16 12:12:39,179 -root -INFO -Validating Spark Object
2024-05-16 12:12:39,179 -Validate -WARNING -started the get_current_date method....
2024-05-16 12:12:42,016 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 16))]
2024-05-16 12:12:42,016 -root -WARNING -Validation done, go forward ...
2024-05-16 12:12:42,016 -root -INFO -Application Done
2024-05-16 12:18:38,815 -root -INFO -i am main method...
2024-05-16 12:18:38,815 -root -INFO -calling spark object...
2024-05-16 12:18:38,815 -Create_spark -INFO -get_spark_object method started
2024-05-16 12:18:38,815 -Create_spark -INFO -master is local
2024-05-16 12:18:47,209 -Create_spark -INFO -Spark object created .....
2024-05-16 12:18:47,209 -root -INFO -Validating Spark Object
2024-05-16 12:18:47,209 -Validate -WARNING -started the get_current_date method....
2024-05-16 12:18:49,904 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 16))]
2024-05-16 12:18:49,904 -root -WARNING -Validation done, go forward ...
2024-05-16 12:18:49,904 -root -INFO -Application Done
2024-05-16 23:46:23,645 -root -INFO -i am main method...
2024-05-16 23:46:23,645 -root -INFO -calling spark object...
2024-05-16 23:46:23,645 -Create_spark -INFO -get_spark_object method started
2024-05-16 23:46:23,645 -Create_spark -INFO -master is local
2024-05-16 23:46:33,682 -Create_spark -INFO -Spark object created .....
2024-05-16 23:46:33,682 -root -INFO -Validating Spark Object
2024-05-16 23:46:33,682 -Validate -WARNING -started the get_current_date method....
2024-05-16 23:46:36,732 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 16))]
2024-05-16 23:46:36,732 -root -WARNING -Validation done, go forward ...
2024-05-16 23:46:36,732 -root -INFO -reading file which of = parquet
2024-05-16 23:46:36,732 -Ingest -WARNING -load files method started...
2024-05-16 23:46:37,209 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-16 23:46:37,219 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-16 23:46:37,928 -root -INFO -Application Done
2024-05-16 23:54:39,325 -root -INFO -i am main method...
2024-05-16 23:54:39,325 -root -INFO -calling spark object...
2024-05-16 23:54:39,325 -Create_spark -INFO -get_spark_object method started
2024-05-16 23:54:39,325 -Create_spark -INFO -master is local
2024-05-16 23:54:49,009 -Create_spark -INFO -Spark object created .....
2024-05-16 23:54:49,010 -root -INFO -Validating Spark Object
2024-05-16 23:54:49,010 -Validate -WARNING -started the get_current_date method....
2024-05-16 23:54:52,010 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 16))]
2024-05-16 23:54:52,010 -root -WARNING -Validation done, go forward ...
2024-05-16 23:54:52,011 -root -INFO -reading file which of = parquet
2024-05-16 23:54:52,011 -Ingest -WARNING -load files method started...
2024-05-16 23:54:52,433 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-16 23:54:52,445 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-16 23:54:53,184 -root -INFO -validating the dataframe.........
2024-05-16 23:54:53,184 -Ingest -WARNING -here to count the records in the df_city
2024-05-16 23:54:53,750 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-16 23:54:53,750 -root -INFO -Application Done
2024-05-22 11:56:49,809 -root -INFO -i am main method...
2024-05-22 11:56:49,809 -root -INFO -calling spark object...
2024-05-22 11:56:49,809 -Create_spark -INFO -get_spark_object method started
2024-05-22 11:56:49,809 -Create_spark -INFO -master is local
2024-05-22 11:56:59,529 -Create_spark -INFO -Spark object created .....
2024-05-22 11:56:59,530 -root -INFO -Validating Spark Object
2024-05-22 11:56:59,530 -Validate -WARNING -started the get_current_date method....
2024-05-22 11:57:02,937 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 11:57:02,938 -root -WARNING -Validation done, go forward ...
2024-05-22 11:57:02,938 -root -INFO -reading file which of = parquet
2024-05-22 11:57:02,938 -Ingest -WARNING -load files method started...
2024-05-22 11:57:03,594 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 11:57:03,608 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 11:57:04,479 -root -INFO -validating the dataframe.........
2024-05-22 11:57:04,479 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 11:57:05,071 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 11:57:05,071 -root -INFO -Application Done
2024-05-22 12:04:16,310 -root -INFO -i am main method...
2024-05-22 12:04:16,311 -root -INFO -calling spark object...
2024-05-22 12:04:16,311 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:04:16,311 -Create_spark -INFO -master is local
2024-05-22 12:04:25,263 -Create_spark -INFO -Spark object created .....
2024-05-22 12:04:25,263 -root -INFO -Validating Spark Object
2024-05-22 12:04:25,263 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:04:28,512 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:04:28,512 -root -WARNING -Validation done, go forward ...
2024-05-22 12:04:28,513 -root -INFO -reading file which of = parquet
2024-05-22 12:04:28,513 -Ingest -WARNING -load files method started...
2024-05-22 12:04:29,000 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:04:29,012 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:04:29,755 -root -INFO -validating the dataframe.........
2024-05-22 12:04:29,755 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:04:30,311 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:04:30,311 -Ingest -WARNING -load files method started...
2024-05-22 12:04:30,387 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:04:30,389 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:04:30,500 -root -INFO -validating the dataframe.........
2024-05-22 12:04:30,500 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 12:04:30,601 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:04:30,601 -root -INFO -Application Done
2024-05-22 12:10:43,616 -root -INFO -i am main method...
2024-05-22 12:10:43,616 -root -INFO -calling spark object...
2024-05-22 12:10:43,616 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:10:43,616 -Create_spark -INFO -master is local
2024-05-22 12:10:53,067 -Create_spark -INFO -Spark object created .....
2024-05-22 12:10:53,067 -root -INFO -Validating Spark Object
2024-05-22 12:10:53,068 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:10:56,647 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:10:56,647 -root -WARNING -Validation done, go forward ...
2024-05-22 12:10:56,648 -root -INFO -reading file which of = parquet
2024-05-22 12:10:56,648 -Ingest -WARNING -load files method started...
2024-05-22 12:10:57,139 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:10:57,151 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:10:57,897 -root -INFO -validating the dataframe.........
2024-05-22 12:10:57,897 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:10:58,403 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:10:58,403 -root -INFO -reading file which of = parquet
2024-05-22 12:10:58,403 -Ingest -WARNING -load files method started...
2024-05-22 12:10:58,475 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:10:58,478 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:10:58,594 -root -INFO -validating the dataframe.........
2024-05-22 12:10:58,594 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 12:10:58,727 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:10:58,727 -root -INFO -Application Done
2024-05-22 12:11:16,115 -root -INFO -i am main method...
2024-05-22 12:11:16,115 -root -INFO -calling spark object...
2024-05-22 12:11:16,115 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:11:16,115 -Create_spark -INFO -master is local
2024-05-22 12:11:24,841 -Create_spark -INFO -Spark object created .....
2024-05-22 12:11:24,841 -root -INFO -Validating Spark Object
2024-05-22 12:11:24,841 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:11:28,095 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:11:28,096 -root -WARNING -Validation done, go forward ...
2024-05-22 12:11:28,096 -root -INFO -reading file which of = parquet
2024-05-22 12:11:28,096 -Ingest -WARNING -load files method started...
2024-05-22 12:11:28,585 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:11:28,598 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:11:29,361 -root -INFO -validating the dataframe.........
2024-05-22 12:11:29,361 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:11:29,881 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:11:29,881 -root -INFO -reading file which of = csv
2024-05-22 12:11:29,881 -Ingest -WARNING -load files method started...
2024-05-22 12:14:00,497 -root -INFO -i am main method...
2024-05-22 12:14:00,497 -root -INFO -calling spark object...
2024-05-22 12:14:00,497 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:14:00,497 -Create_spark -INFO -master is local
2024-05-22 12:14:09,282 -Create_spark -INFO -Spark object created .....
2024-05-22 12:14:09,282 -root -INFO -Validating Spark Object
2024-05-22 12:14:09,282 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:14:12,692 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:14:12,692 -root -WARNING -Validation done, go forward ...
2024-05-22 12:14:12,693 -root -INFO -reading file which of = parquet
2024-05-22 12:14:12,693 -Ingest -WARNING -load files method started...
2024-05-22 12:14:13,201 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:14:13,215 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:14:13,943 -root -INFO -validating the dataframe.........
2024-05-22 12:14:13,943 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:14:14,487 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:14:14,488 -root -INFO -reading file which of = csv
2024-05-22 12:14:14,488 -Ingest -WARNING -load files method started...
2024-05-22 12:14:42,712 -root -INFO -i am main method...
2024-05-22 12:14:42,712 -root -INFO -calling spark object...
2024-05-22 12:14:42,712 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:14:42,712 -Create_spark -INFO -master is local
2024-05-22 12:14:56,979 -Create_spark -INFO -Spark object created .....
2024-05-22 12:14:56,979 -root -INFO -Validating Spark Object
2024-05-22 12:14:56,979 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:15:00,435 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:15:00,435 -root -WARNING -Validation done, go forward ...
2024-05-22 12:15:00,436 -root -INFO -reading file which of = parquet
2024-05-22 12:15:00,436 -Ingest -WARNING -load files method started...
2024-05-22 12:15:00,924 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:15:00,937 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:15:01,674 -root -INFO -validating the dataframe.........
2024-05-22 12:15:01,674 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:15:02,209 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:15:02,209 -root -INFO -reading file which of = csv
2024-05-22 12:15:02,209 -Ingest -WARNING -load files method started...
2024-05-22 12:15:02,895 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 12:15:02,898 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 12:15:03,094 -root -INFO -validating the dataframe.........
2024-05-22 12:15:03,094 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 12:15:03,242 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 12:15:03,243 -root -INFO -Application Done
2024-05-22 12:25:52,300 -root -INFO -i am main method...
2024-05-22 12:25:52,300 -root -INFO -calling spark object...
2024-05-22 12:25:52,300 -Create_spark -INFO -get_spark_object method started
2024-05-22 12:25:52,300 -Create_spark -INFO -master is local
2024-05-22 12:26:01,330 -Create_spark -INFO -Spark object created .....
2024-05-22 12:26:01,330 -root -INFO -Validating Spark Object
2024-05-22 12:26:01,330 -Validate -WARNING -started the get_current_date method....
2024-05-22 12:26:04,658 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 12:26:04,658 -root -WARNING -Validation done, go forward ...
2024-05-22 12:26:04,658 -root -INFO -reading file which of = parquet
2024-05-22 12:26:04,658 -Ingest -WARNING -load files method started...
2024-05-22 12:26:05,136 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 12:26:05,148 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 12:26:05,889 -root -INFO -validating the dataframe.........
2024-05-22 12:26:05,889 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 12:26:06,409 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 12:26:06,410 -root -INFO -reading file which of = csv
2024-05-22 12:26:06,410 -Ingest -WARNING -load files method started...
2024-05-22 12:26:07,041 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 12:26:07,043 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 12:26:07,204 -root -INFO -validating the dataframe.........
2024-05-22 12:26:07,204 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 12:26:07,347 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 12:26:07,347 -root -INFO -Application Done
2024-05-22 13:00:23,159 -root -INFO -i am main method...
2024-05-22 13:00:23,159 -root -INFO -calling spark object...
2024-05-22 13:00:23,159 -Create_spark -INFO -get_spark_object method started
2024-05-22 13:00:23,159 -Create_spark -INFO -master is local
2024-05-22 13:00:32,802 -Create_spark -INFO -Spark object created .....
2024-05-22 13:00:32,802 -root -INFO -Validating Spark Object
2024-05-22 13:00:32,802 -Validate -WARNING -started the get_current_date method....
2024-05-22 13:00:35,922 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 13:00:35,922 -root -WARNING -Validation done, go forward ...
2024-05-22 13:00:35,922 -root -INFO -reading file which of = parquet
2024-05-22 13:00:35,922 -Ingest -WARNING -load files method started...
2024-05-22 13:00:36,415 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 13:00:36,428 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 13:00:37,159 -root -INFO -validating the dataframe.........
2024-05-22 13:00:37,159 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 13:00:37,671 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 13:00:37,671 -root -INFO -reading file which of = csv
2024-05-22 13:00:37,671 -Ingest -WARNING -load files method started...
2024-05-22 13:00:38,267 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 13:00:38,269 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 13:00:38,270 -root -INFO -validating the dataframe.........
2024-05-22 13:00:38,270 -root -INFO -implementing data_processing methods ....
2024-05-22 13:00:38,270 -Data_processing -WARNING -data clean method started ...
2024-05-22 13:00:38,270 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 13:10:40,255 -root -INFO -i am main method...
2024-05-22 13:10:40,256 -root -INFO -calling spark object...
2024-05-22 13:10:40,256 -Create_spark -INFO -get_spark_object method started
2024-05-22 13:10:40,256 -Create_spark -INFO -master is local
2024-05-22 13:10:49,159 -Create_spark -INFO -Spark object created .....
2024-05-22 13:10:49,159 -root -INFO -Validating Spark Object
2024-05-22 13:10:49,159 -Validate -WARNING -started the get_current_date method....
2024-05-22 13:10:52,356 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 13:10:52,356 -root -WARNING -Validation done, go forward ...
2024-05-22 13:10:52,356 -root -INFO -reading file which of = parquet
2024-05-22 13:10:52,356 -Ingest -WARNING -load files method started...
2024-05-22 13:10:52,847 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 13:10:52,859 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 13:10:53,602 -root -INFO -validating the dataframe.........
2024-05-22 13:10:53,603 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 13:10:54,107 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 13:10:54,108 -root -INFO -reading file which of = csv
2024-05-22 13:10:54,108 -Ingest -WARNING -load files method started...
2024-05-22 13:10:54,730 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 13:10:54,732 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 13:10:54,895 -root -INFO -validating the dataframe.........
2024-05-22 13:10:54,895 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 13:10:55,035 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 13:10:55,036 -root -INFO -implementing data_processing methods ....
2024-05-22 13:10:55,036 -Data_processing -WARNING -data clean method started ...
2024-05-22 13:10:55,036 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 13:11:42,774 -root -INFO -i am main method...
2024-05-22 13:11:42,774 -root -INFO -calling spark object...
2024-05-22 13:11:42,774 -Create_spark -INFO -get_spark_object method started
2024-05-22 13:11:42,774 -Create_spark -INFO -master is local
2024-05-22 13:11:52,017 -Create_spark -INFO -Spark object created .....
2024-05-22 13:11:52,017 -root -INFO -Validating Spark Object
2024-05-22 13:11:52,017 -Validate -WARNING -started the get_current_date method....
2024-05-22 13:11:55,152 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 13:11:55,152 -root -WARNING -Validation done, go forward ...
2024-05-22 13:11:55,152 -root -INFO -reading file which of = parquet
2024-05-22 13:11:55,152 -Ingest -WARNING -load files method started...
2024-05-22 13:11:55,629 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 13:11:55,641 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 13:11:56,355 -root -INFO -validating the dataframe.........
2024-05-22 13:11:56,355 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 13:11:56,871 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 13:11:56,872 -root -INFO -reading file which of = csv
2024-05-22 13:11:56,872 -Ingest -WARNING -load files method started...
2024-05-22 13:11:57,558 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 13:11:57,561 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 13:11:57,745 -root -INFO -validating the dataframe.........
2024-05-22 13:11:57,745 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 13:11:57,923 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 13:11:57,923 -root -INFO -implementing data_processing methods ....
2024-05-22 13:11:57,923 -Data_processing -WARNING -data clean method started ...
2024-05-22 13:11:57,923 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 15:03:40,350 -root -INFO -i am main method...
2024-05-22 15:03:40,350 -root -INFO -calling spark object...
2024-05-22 15:03:40,350 -Create_spark -INFO -get_spark_object method started
2024-05-22 15:03:40,350 -Create_spark -INFO -master is local
2024-05-22 15:03:49,595 -Create_spark -INFO -Spark object created .....
2024-05-22 15:03:49,596 -root -INFO -Validating Spark Object
2024-05-22 15:03:49,596 -Validate -WARNING -started the get_current_date method....
2024-05-22 15:03:52,953 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 15:03:52,953 -root -WARNING -Validation done, go forward ...
2024-05-22 15:03:52,953 -root -INFO -reading file which of = parquet
2024-05-22 15:03:52,953 -Ingest -WARNING -load files method started...
2024-05-22 15:03:53,453 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 15:03:53,465 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 15:03:54,306 -root -INFO -validating the dataframe.........
2024-05-22 15:03:54,306 -Ingest -WARNING -here to count the records in the df_city
2024-05-22 15:03:54,832 -Ingest -WARNING -number of records present in the DataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string] are:1000
2024-05-22 15:03:54,832 -root -INFO -reading file which of = csv
2024-05-22 15:03:54,832 -Ingest -WARNING -load files method started...
2024-05-22 15:03:55,513 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 15:03:55,515 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 15:03:55,706 -root -INFO -validating the dataframe.........
2024-05-22 15:03:55,706 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 15:03:55,877 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 15:03:55,877 -root -INFO -implementing data_processing methods ....
2024-05-22 15:03:55,877 -Data_processing -WARNING -data clean method started ...
2024-05-22 15:03:55,877 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 15:06:11,390 -root -INFO -i am main method...
2024-05-22 15:06:11,390 -root -INFO -calling spark object...
2024-05-22 15:06:11,390 -Create_spark -INFO -get_spark_object method started
2024-05-22 15:06:11,390 -Create_spark -INFO -master is local
2024-05-22 15:06:20,401 -Create_spark -INFO -Spark object created .....
2024-05-22 15:06:20,401 -root -INFO -Validating Spark Object
2024-05-22 15:06:20,401 -Validate -WARNING -started the get_current_date method....
2024-05-22 15:06:23,617 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 15:06:23,617 -root -WARNING -Validation done, go forward ...
2024-05-22 15:06:23,617 -root -INFO -reading file which of = parquet
2024-05-22 15:06:23,617 -Ingest -WARNING -load files method started...
2024-05-22 15:06:24,103 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 15:06:24,114 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 15:06:24,114 -root -INFO -validating the dataframe.........
2024-05-22 15:06:24,115 -root -INFO -reading file which of = csv
2024-05-22 15:06:24,115 -Ingest -WARNING -load files method started...
2024-05-22 15:06:24,995 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 15:06:24,998 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 15:06:25,273 -root -INFO -validating the dataframe.........
2024-05-22 15:06:25,273 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 15:06:25,723 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 15:06:25,723 -root -INFO -implementing data_processing methods ....
2024-05-22 15:06:25,723 -Data_processing -WARNING -data clean method started ...
2024-05-22 15:06:25,723 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 15:06:25,756 -Data_processing -WARNING -selecting required columns from OLTP and converting them into uppercase if they required...
2024-05-22 15:06:25,765 -Data_processing -WARNING -data_clean() method executed done, for frwd... 
2024-05-22 15:06:26,249 -root -INFO -Application Done
2024-05-22 15:17:44,841 -root -INFO -i am main method...
2024-05-22 15:17:44,841 -root -INFO -calling spark object...
2024-05-22 15:17:44,841 -Create_spark -INFO -get_spark_object method started
2024-05-22 15:17:44,841 -Create_spark -INFO -master is local
2024-05-22 15:17:53,891 -Create_spark -INFO -Spark object created .....
2024-05-22 15:17:53,891 -root -INFO -Validating Spark Object
2024-05-22 15:17:53,891 -Validate -WARNING -started the get_current_date method....
2024-05-22 15:17:57,343 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 15:17:57,343 -root -WARNING -Validation done, go forward ...
2024-05-22 15:17:57,344 -root -INFO -reading file which of = parquet
2024-05-22 15:17:57,344 -Ingest -WARNING -load files method started...
2024-05-22 15:17:57,879 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 15:17:57,892 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 15:17:57,892 -root -INFO -validating the dataframe.........
2024-05-22 15:17:57,893 -root -INFO -reading file which of = csv
2024-05-22 15:17:57,893 -Ingest -WARNING -load files method started...
2024-05-22 15:17:58,854 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 15:17:58,856 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 15:17:59,153 -root -INFO -validating the dataframe.........
2024-05-22 15:17:59,153 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 15:17:59,669 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 15:17:59,669 -root -INFO -implementing data_processing methods ....
2024-05-22 15:17:59,669 -Data_processing -WARNING -data clean method started ...
2024-05-22 15:17:59,669 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 15:17:59,703 -Data_processing -WARNING -selecting required columns from OLTP and converting them into uppercase if they required...
2024-05-22 15:17:59,714 -Data_processing -WARNING -data_clean() method executed done, for frwd... 
2024-05-22 15:18:00,272 -root -INFO -Application Done
2024-05-22 16:51:36,504 -root -INFO -i am main method...
2024-05-22 16:51:36,504 -root -INFO -calling spark object...
2024-05-22 16:51:36,504 -Create_spark -INFO -get_spark_object method started
2024-05-22 16:51:36,504 -Create_spark -INFO -master is local
2024-05-22 16:51:45,289 -Create_spark -INFO -Spark object created .....
2024-05-22 16:51:45,289 -root -INFO -Validating Spark Object
2024-05-22 16:51:45,289 -Validate -WARNING -started the get_current_date method....
2024-05-22 16:51:48,513 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 22))]
2024-05-22 16:51:48,513 -root -WARNING -Validation done, go forward ...
2024-05-22 16:51:48,513 -root -INFO -reading file which of = parquet
2024-05-22 16:51:48,513 -Ingest -WARNING -load files method started...
2024-05-22 16:51:48,985 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-22 16:51:48,997 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-22 16:51:48,997 -root -INFO -validating the dataframe.........
2024-05-22 16:51:48,997 -root -INFO -reading file which of = csv
2024-05-22 16:51:48,998 -Ingest -WARNING -load files method started...
2024-05-22 16:51:49,842 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-22 16:51:49,844 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-22 16:51:50,101 -root -INFO -validating the dataframe.........
2024-05-22 16:51:50,101 -Ingest -WARNING -here to count the records in the df_movies
2024-05-22 16:51:50,538 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-22 16:51:50,539 -root -INFO -implementing data_processing methods ....
2024-05-22 16:51:50,539 -Data_processing -WARNING -data clean method started ...
2024-05-22 16:51:50,539 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-22 16:51:50,570 -Data_processing -WARNING -selecting required columns from OLTP and converting them into uppercase if they required...
2024-05-22 16:51:50,578 -Data_processing -WARNING -data_clean() method executed done, for frwd... 
2024-05-22 16:51:50,957 -root -INFO -schema of of table DataFrame[fname: string, lname: string, email: string, gender: string, country: string, salary: double]
2024-05-22 16:51:51,060 -root -INFO -schema of of table DataFrame[name: string, year: int, score: double, country: string, runtime: double]
2024-05-22 16:51:51,060 -root -INFO -Application Done
2024-05-24 11:44:46,535 -root -INFO -i am main method...
2024-05-24 11:44:46,536 -root -INFO -calling spark object...
2024-05-24 11:44:46,536 -Create_spark -INFO -get_spark_object method started
2024-05-24 11:44:46,536 -Create_spark -INFO -master is local
2024-05-24 11:44:56,325 -Create_spark -INFO -Spark object created .....
2024-05-24 11:44:56,325 -root -INFO -Validating Spark Object
2024-05-24 11:44:56,326 -Validate -WARNING -started the get_current_date method....
2024-05-24 11:44:59,758 -root -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2024, 5, 24))]
2024-05-24 11:44:59,758 -root -WARNING -Validation done, go forward ...
2024-05-24 11:44:59,758 -root -INFO -reading file which of = parquet
2024-05-24 11:44:59,758 -Ingest -WARNING -load files method started...
2024-05-24 11:45:00,300 -Ingest -WARNING -dataframe created successfully which is of parquet
2024-05-24 11:45:00,312 -root -INFO -display the dataframeDataFrame[registration_dttm: timestamp, id: int, first_name: string, last_name: string, email: string, gender: string, ip_address: string, cc: string, country: string, birthdate: string, salary: double, title: string, comments: string]
2024-05-24 11:45:00,312 -root -INFO -validating the dataframe.........
2024-05-24 11:45:00,313 -root -INFO -reading file which of = csv
2024-05-24 11:45:00,313 -Ingest -WARNING -load files method started...
2024-05-24 11:45:01,236 -Ingest -WARNING -dataframe created successfully which is of csv
2024-05-24 11:45:01,238 -root -INFO -display the dataframeDataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double]
2024-05-24 11:45:01,502 -root -INFO -validating the dataframe.........
2024-05-24 11:45:01,502 -Ingest -WARNING -here to count the records in the df_movies
2024-05-24 11:45:01,989 -Ingest -WARNING -number of records present in the DataFrame[name: string, rating: string, genre: string, year: int, released: string, score: double, votes: double, director: string, writer: string, star: string, country: string, budget: double, gross: double, company: string, runtime: double] are:7668
2024-05-24 11:45:01,989 -root -INFO -implementing data_processing methods ....
2024-05-24 11:45:01,989 -Data_processing -WARNING -data clean method started ...
2024-05-24 11:45:01,989 -Data_processing -WARNING -selecting required columns from OLAP and converting them into uppercase if they required...
2024-05-24 11:45:02,020 -Data_processing -WARNING -selecting required columns from OLTP and converting them into uppercase if they required...
2024-05-24 11:45:02,028 -Data_processing -WARNING -data_clean() method executed done, for frwd... 
2024-05-24 11:45:02,425 -root -INFO -schema of of table DataFrame[fname: string, lname: string, email: string, gender: string, country: string, salary: double]
2024-05-24 11:45:02,527 -root -INFO -schema of of table DataFrame[name: string, year: int, score: double, country: string, runtime: double]
2024-05-24 11:45:02,528 -root -INFO -Application Done
